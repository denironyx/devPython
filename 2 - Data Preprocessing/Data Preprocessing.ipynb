{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font size=\"6\">01. Data Preprocessing</font><a class=\"anchor\"><a id='toc'></a></b><br><br>\n",
    "This notebook requires previous knowledge in Pandas library. Feel free to complement your knowledge with online tutorials such as:<br>\n",
    "https://learn.datacamp.com/courses/data-manipulation-with-pandas <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='#BFD72F'>1. Importing Data</font> <a class=\"anchor\" id=\"first-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to local repository\n",
    "from os import getcwd\n",
    "\n",
    "path = getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1** - Import the pandas library and define the alias as 'pd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2** - Read the excel file 'tugas.xlsx' and save it to the object `data` using the pandas method `pd.read_excel()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dataset\n",
    "tugas = pd.read_excel( 'data/tugas.xlsx', engine='openpyxl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"data\">\n",
    "    \n",
    "## 1.1. The data available: Customer information\n",
    "\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Customer ID**\n",
    "\n",
    "##### Sociodemographic data:\n",
    "- **Gender**\n",
    "- **Age** \n",
    "- **Education**\n",
    "- **Marital Status**\n",
    "- **Dependents**\n",
    "- **Income**\n",
    "\n",
    "##### Firmographic data:\n",
    "- **RFM**\n",
    "- **Product purchase history (Clothes / House Keeping / Kitchen / Small Appliances / Toys)**\n",
    "- **Channel usage**\n",
    "- **Recommendation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='#BFD72F'>2. Data Preparation</font> <a class=\"anchor\" id=\"second-bullet\"></a>\n",
    "\n",
    "\n",
    "* [2.1 - Data Preparation](#preparation)\n",
    "* [2.2 - Data Cleaning](#cleaning)\n",
    "* [2.3 - Feature Engineering](#transformation)\n",
    "* [2.4 - Scaling Data](#normalize)\n",
    "* [2.5 - Correlations](#corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"preparation\">\n",
    "\n",
    "## 2.1.  Data Preparation\n",
    "\n",
    "</a>\n",
    "\n",
    "[Back to Data Preparation](#second-bullet) <br><br>\n",
    "In this phase, we are going to view some useful commands to prepare the dataset to suffer preprocessing tasks.\n",
    "\n",
    "We are going to learn how to:\n",
    "- Make copies of the original dataset; <br>\n",
    "- Drop columns; <br>\n",
    "- Rename columns; <br>\n",
    "- Set the index; <br>\n",
    "- Convert data types; <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1. Duplicated Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do we have duplicated rows? We can check that using the pandas method `duplicated()`. When using this method there are some parameters we can provide to it. We can use `subset` to only check for duplicates within a specific subset of columns. We can set the `keep` parameter to 'first', 'last' or False. Setting the `keep` parameter to 'first' will signal all duplicates as True except for their first occurrence. Similarly, setting `keep` to 'last' will signal all duplicate records as True except for their last occurrence. If we want to see all duplicate records we should set `keep` to False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Step 3\n",
    "tugas[tugas.duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that we have two rows that are duplicated. <br>\n",
    "\n",
    "**Step 4 -** To drop the duplicate row(s), we can use the `drop_duplicates()` method. <br>\n",
    "Most methods in pandas do not apply the changes directly to the object. In this way, and in this case, we need to define the parameter inplace as `inplace = True` so the changes are applied directly on the dataset. <br>\n",
    "Once again, `drop_duplicates` also has a `keep` parameter. The default value for this parameter is 'first', meaning it will keep first occurrences of duplicate rows in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4\n",
    "tugas.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the data is clean from duplicate rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tugas[tugas.duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2. Make a copy from the original dataset\n",
    "\n",
    "*   List item\n",
    "*   List item\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9650cb4e16cdd4a8e8e2d128bf38d875813998db22a3c986335f89e0cb4d7bb2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
